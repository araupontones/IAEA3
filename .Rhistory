name = glue("{toupper(stri_trans_general(q0003_0002, 'Latin-ASCII'))}, {str_to_sentence(q0003_0001)}")
) %>%
relocate(country, name, role) %>%
select(-starts_with("Collector"),
-starts_with("Custom"),
-starts_with('q0003'),
-starts_with('p0')) %>%
mutate_all(as.character) %>%
mutate_all(function(x){ifelse(x == "", NA_character_, x)}) %>%
rowwise() %>%
mutate(answered = sum(!is.na(across(starts_with('q'))))) %>%
arrange(country,name, role,StartDate) %>%
group_by_at(by) %>%
mutate(times_submitted = n(),
int = row_number()) %>%
relocate(country, name,role, answered, times_submitted,  int) %>%
.[,1:7] %>%
pivot_wider(id_cols = c(all_of(by), times_submitted),
names_prefix = "answers_",
names_from = int,
values_from = answered)
}
wide_country <- create_wide(by = c("country"))
wide_name <- create_wide(by = c("country", "name", "role"))
View(wide_name)
wide_name <- create_wide(by = c("country", "name", "role"))
create_wide <- function(by){
raw_data %>%
#mutate_all(as.character)
rename(country = q0002,
role = q0001) %>%
mutate(country = susor_get_stata_labels(country),
role = susor_get_stata_labels(role),
name = glue("{toupper(stri_trans_general(q0003_0002, 'Latin-ASCII'))}, {str_to_sentence(q0003_0001)}")
) %>%
relocate(country, name, role) %>%
select(-starts_with("Collector"),
-starts_with("Custom"),
-starts_with('q0003'),
-starts_with('p0')) %>%
mutate_all(as.character) %>%
mutate_all(function(x){ifelse(x == "", NA_character_, x)}) %>%
rowwise() %>%
mutate(answered = sum(!is.na(across(starts_with('q'))))) %>%
arrange(country,name, role,StartDate) %>%
group_by_at(by) %>%
mutate(times_submitted = n(),
int = row_number()) %>%
relocate(country, name,role, answered, times_submitted,  int) %>%
.[,1:7] %>%
pivot_wider(id_cols = c(all_of(by), times_submitted),
names_prefix = "answers_",
names_from = int,
values_from = answered)
}
wide_country <- create_wide(by = c("country"))
wide_name <- create_wide(by = c("country", "name", "role"))
wide_name <- create_wide(by = c("country", "name"))
raw_data %>%
#mutate_all(as.character)
rename(country = q0002,
role = q0001) %>%
mutate(country = susor_get_stata_labels(country),
role = susor_get_stata_labels(role),
name = glue("{toupper(stri_trans_general(q0003_0002, 'Latin-ASCII'))}, {str_to_sentence(q0003_0001)}")
) %>%
relocate(country, name, role) %>%
select(-starts_with("Collector"),
-starts_with("Custom"),
-starts_with('q0003'),
-starts_with('p0')) %>%
mutate_all(as.character) %>%
mutate_all(function(x){ifelse(x == "", NA_character_, x)}) %>%
rowwise() %>%
mutate(answered = sum(!is.na(across(starts_with('q'))))) %>%
arrange(country,name, role,StartDate) %>%
group_by_at(by) %>%
mutate(times_submitted = n(),
int = row_number()) %>%
relocate(country, name,role, answered, times_submitted,  int) %>%
.[,1:8] %>%
pivot_wider(id_cols = c(all_of(by), times_submitted),
names_prefix = "answers_",
names_from = int,
values_from = answered)
create_wide <- function(by){
raw_data %>%
#mutate_all(as.character)
rename(country = q0002,
role = q0001) %>%
mutate(country = susor_get_stata_labels(country),
role = susor_get_stata_labels(role),
name = glue("{toupper(stri_trans_general(q0003_0002, 'Latin-ASCII'))}, {str_to_sentence(q0003_0001)}")
) %>%
relocate(country, name, role) %>%
select(-starts_with("Collector"),
-starts_with("Custom"),
-starts_with('q0003'),
-starts_with('p0')) %>%
mutate_all(as.character) %>%
mutate_all(function(x){ifelse(x == "", NA_character_, x)}) %>%
rowwise() %>%
mutate(answered = sum(!is.na(across(starts_with('q'))))) %>%
arrange(country,name, role,StartDate) %>%
group_by_at(by) %>%
mutate(times_submitted = n(),
int = row_number()) %>%
relocate(country, name,role, answered, times_submitted,  int) %>%
.[,1:8] %>%
pivot_wider(id_cols = c(all_of(by), times_submitted),
names_prefix = "answers_",
names_from = int,
values_from = answered)
}
wide_name <- create_wide(by = c("country", "name", "role"))
wide_name <- create_wide(by = c("country", "name", "role"))
dupes <- get_dupes(wide_name)
dupes <- janitor::get_dupes(wide_name)
dupes <- janitor::get_dupes(wide_name, name)
View(dupes)
export_checks <- function(by){
if(by == 'name'){
wide = wide_name
criteria = "$C2>1"
exfile = 'NLOs'
} else {
wide = wide_country
criteria = "$B2>1"
exfile = 'countries'
}
rows <- nrow(wide) + 1
cols <- ncol(wide)
wb <- openxlsx::createWorkbook()
addWorksheet(wb, 'duplicates')
writeData(wb, 'duplicates', wide, rowNames = F, colNames = T)
#header
#styles
style_header <- createStyle(fontName = 'Open Sans',
fontSize = 9,
fontColour = '#FFFFFF',
textDecoration = 'bold',
bgFill = 'black',
border = "TopBottomLeftRight",
borderColour = '#FFFFFF')
addStyle(wb, "duplicates", style = style_header, rows = 1, cols = 1:cols)
#format normal
normal_style= createStyle(fontName = 'Open Sans',
fontSize = 8,
fontColour = 'black',
border = "TopBottomLeftRight",
borderColour = 'black'
)
addStyle(wb, 'duplicates', normal_style, cols = 1:cols, rows = 2:rows, gridExpand = T)
#conditional formatting
dup_style= createStyle(fontName = 'Open Sans',
fontSize = 8,
fontColour = 'black',
border = "TopBottomLeftRight",
borderColour = 'black',
bgFill = '#FDED65')
conditionalFormatting(wb, "duplicates",
fontSize = 8,
cols = 1:cols,
rows = 2:rows,
rule = criteria,
style = dup_style
)
setColWidths(wb, 'duplicates', cols = 1, widths = 29)
setColWidths(wb, 'duplicates', cols =2, widths = 40)
freezePane(wb, "duplicates", firstActiveRow = 2)
openxlsx::saveWorkbook(wb, glue('data/7.NLO/5.checks/check_duplicates_{exfile}.xlsx'), overwrite = T)
message('exported')
}
export_checks('name')
library(openxlsx)
export_checks('name')
export_checks <- function(by){
if(by == 'name'){
wide = wide_name
criteria = "$D2>1"
exfile = 'NLOs'
} else {
wide = wide_country
criteria = "$B2>1"
exfile = 'countries'
}
rows <- nrow(wide) + 1
cols <- ncol(wide)
wb <- openxlsx::createWorkbook()
addWorksheet(wb, 'duplicates')
writeData(wb, 'duplicates', wide, rowNames = F, colNames = T)
#header
#styles
style_header <- createStyle(fontName = 'Open Sans',
fontSize = 9,
fontColour = '#FFFFFF',
textDecoration = 'bold',
bgFill = 'black',
border = "TopBottomLeftRight",
borderColour = '#FFFFFF')
addStyle(wb, "duplicates", style = style_header, rows = 1, cols = 1:cols)
#format normal
normal_style= createStyle(fontName = 'Open Sans',
fontSize = 8,
fontColour = 'black',
border = "TopBottomLeftRight",
borderColour = 'black'
)
addStyle(wb, 'duplicates', normal_style, cols = 1:cols, rows = 2:rows, gridExpand = T)
#conditional formatting
dup_style= createStyle(fontName = 'Open Sans',
fontSize = 8,
fontColour = 'black',
border = "TopBottomLeftRight",
borderColour = 'black',
bgFill = '#FDED65')
conditionalFormatting(wb, "duplicates",
fontSize = 8,
cols = 1:cols,
rows = 2:rows,
rule = criteria,
style = dup_style
)
setColWidths(wb, 'duplicates', cols = 1, widths = 29)
setColWidths(wb, 'duplicates', cols =2, widths = 40)
freezePane(wb, "duplicates", firstActiveRow = 2)
openxlsx::saveWorkbook(wb, glue('data/7.NLO/5.checks/check_duplicates_{exfile}.xlsx'), overwrite = T)
message('exported')
}
export_checks('name')
#QA response rates by countries
library(dplyr)
library(tidyr)
library(rio)
library(janitor)
library(susor)
library(openxlsx)
library(scales)
library(glue)
gmdacr::load_functions('functions')
#define paths =================================================================
raw_dir <- 'data/6.data-collection/1.raw/cp'
raw_data <- import(file.path(raw_dir, 'cp.rds'))
# gStatus ======================================================================
status <- raw_data %>%
relocate(Country_name, Name, email, interview__status, n_questions_unanswered)
#summary by country
by_country <- status %>%
group_by(Country_name) %>%
summarise(Sampled = n(),
Bounced = sum(interview__status == "Bounced"),
Accessed = sum(interview__status %in% c("Submitted", "Responding")),
Submitted = sum(interview__status == "Submitted"),
Avg_questions_unanswered = round(mean(n_questions_unanswered, na.rm = T),1),
response_rate = Submitted / Sampled
)
#Get row with totals totals --------------------------------------------------------------------
TOTALS <- tibble(
Country_name = "TOTAL",
Sampled = nrow(status),
Bounced = sum(by_country$Bounced),
Accessed = sum(by_country$Accessed),
Submitted = sum(by_country$Submitted),
Avg_questions_unanswered = round(mean(by_country$Avg_questions_unanswered, na.rm = T),1),
response_rate = Submitted/Sampled
)
#Define response rate
by_country_totals <- rbind(by_country, TOTALS) %>%
mutate(response_rate = scales::percent(response_rate, accuracy = .1),
Avg_questions_unanswered = ifelse(is.na(Avg_questions_unanswered), NA_real_, Avg_questions_unanswered))
# export summary by country
crate_xlsx_by_country(db = by_country_totals,
exfile = glue::glue("data/6.data-collection/2.response_rates/responses_by_country_{Sys.Date()}.xlsx")
)
total_countries = length(unique(by_country$Country_name))
havent_submitted =sum(by_country$Submitted ==0)
perc_havent = scales::percent(havent_submitted/total_countries)
sample_n = nrow(sample)
open = 4168
open_perc =scales::percent(open/sample_n)
accessed = comp = by_country_totals$Accessed[by_country_totals$Country_name == 'TOTAL']
acc_pers = percent(accessed/sample_n,accuracy = .01)
comp = by_country_totals$Submitted[by_country_totals$Country_name == 'TOTAL']
comp_pers = percent(comp/sample_n, accuracy = .01)
knitr::combine_words(sort(by_country$Country_name[by_country$Submitted==0]), sep = ", ")
avg_unanswered = round(mean(status$n_questions_unanswered[status$interview__status == "Submitted"], na.rm = T),1)
max_unanswered = round(max(status$n_questions_unanswered[status$interview__status == "Submitted"], na.rm = T),1)
glue::glue('from the {total_countries} countries in the sample, {havent_submitted} ({perc_havent}) have not submitted any interview yet.')
glue::glue('{open} ({open_perc}) have opened the invitation email')
glue('{accessed} ({acc_pers}) have accessed')
glue('{comp} ({comp_pers}) have submitted')
glue('The submitted interview with the maximum number of unanswered question, has {max_unanswered} unanswered')
glue("The average submitted interview has a total of {avg_unanswered} question")
#load dependencies --------------------------------------------------------------
#source("R_/5.QA/utils_QA.R")
library(dplyr)
library(httr)
library(stringr)
library(lubridate)
library(rio)
library(janitor)
library(susor)
#dfine parameters --------------------------------------------------------------
#sample_girls<- rio::import(survey_girls_sample_path)
questionnaire <- "cp"
sample_file <- 'data/2.sample/cps_sample_corrected.csv'
sample <- import(sample_file)
bounces <- import('data/4.campaigns/bounces_Oct_16_2023.csv') %>%
select(email =`Email Address`,
bounce = `Bounce Type`)
#download data ----------------------------------------------------------------
#login
#Import list of interviewers logged in Survey Solutions -----------------------
susor::susor_login(susor_server = "https://www.pulpodata.solutions",
susor_user = "araupontones",
susor_password = "Seguridad1",
susor_dir_downloads = 'data/6.data-collection/0.downloads',
susor_dir_raw = 'data/6.data-collection/1.raw',
limit = 100,
ofset = 1
)
#Download all versions of the questionnaire ----------------------------------
#get versions ---------------------------------------------------------------
versions <- susor_questionnaires$Version[susor_questionnaires$Variable == questionnaire]
downloads <- lapply(versions, function(x){
susor::susor_export_file(susor_qn_variable = questionnaire,
susor_qn_version = x,
susor_format = "STATA"
)
})
#append all versions ---------------------------------------------------------
susor::susor_append_versions(susor_qn_variable = questionnaire,
susor_format = "STATA")
#read raw data -----------------------------------------------------
raw_data <- rio::import(file.path(susor_dir_raw, questionnaire, 'cp.dta'))
#count missing values
raw_data$na_count <- apply(raw_data, 1, function(x) sum(is.na(x)))
raw_no_dupes<- raw_data %>%
#Keep only one observation by counterpart
group_by(counterpart) %>%
filter(na_count == min(na_count)) %>%
filter(n_questions_unanswered == min(n_questions_unanswered)) %>%
filter(row_number() == 1) %>%
ungroup() %>%
relocate(counterpart, na_count, n_questions_unanswered, interview__status)
#count number of  duplicates
dupes <- get_dupes(raw_no_dupes, counterpart)
#join with sample
raw_with_sample <- raw_no_dupes %>%
right_join(sample, by = c('counterpart' = 'cp_id')) %>%
mutate(across(c(interview__status, country), function(x)susor_get_stata_labels(x))) %>%
left_join(bounces) %>%
mutate(interview__status = case_when(!is.na(bounce) ~ "Bounced",
is.na(interview__status) ~ "Not Started",
#cases when user did not "completed the interview"
interview__status == "InterviewerAssigned" &
na_count <= 70 &
n_questions_unanswered <=3 ~ "Submitted",
interview__status == "InterviewerAssigned" ~ "Responding",
interview__status == "Completed" ~ "Submitted"
))
tabyl(raw_with_sample, interview__status)
#export raw data
export(raw_with_sample, file.path(susor_dir_raw, questionnaire, 'cp.rds'))
glue::glue('from the {total_countries} countries in the sample, {havent_submitted} ({perc_havent}) have not submitted any interview yet.')
glue::glue('{open} ({open_perc}) have opened the invitation email')
glue('{accessed} ({acc_pers}) have accessed')
glue('{comp} ({comp_pers}) have submitted')
glue('The submitted interview with the maximum number of unanswered question, has {max_unanswered} unanswered')
glue("The average submitted interview has a total of {avg_unanswered} question")
glue('{accessed} ({acc_pers}) have accessed')
#QA response rates by countries
library(dplyr)
library(tidyr)
library(rio)
library(janitor)
library(susor)
library(openxlsx)
library(scales)
library(glue)
gmdacr::load_functions('functions')
#define paths =================================================================
raw_dir <- 'data/6.data-collection/1.raw/cp'
raw_data <- import(file.path(raw_dir, 'cp.rds'))
# gStatus ======================================================================
status <- raw_data %>%
relocate(Country_name, Name, email, interview__status, n_questions_unanswered)
#summary by country
by_country <- status %>%
group_by(Country_name) %>%
summarise(Sampled = n(),
Bounced = sum(interview__status == "Bounced"),
Accessed = sum(interview__status %in% c("Submitted", "Responding")),
Submitted = sum(interview__status == "Submitted"),
Avg_questions_unanswered = round(mean(n_questions_unanswered, na.rm = T),1),
response_rate = Submitted / Sampled
)
#Get row with totals totals --------------------------------------------------------------------
TOTALS <- tibble(
Country_name = "TOTAL",
Sampled = nrow(status),
Bounced = sum(by_country$Bounced),
Accessed = sum(by_country$Accessed),
Submitted = sum(by_country$Submitted),
Avg_questions_unanswered = round(mean(by_country$Avg_questions_unanswered, na.rm = T),1),
response_rate = Submitted/Sampled
)
#Define response rate
by_country_totals <- rbind(by_country, TOTALS) %>%
mutate(response_rate = scales::percent(response_rate, accuracy = .1),
Avg_questions_unanswered = ifelse(is.na(Avg_questions_unanswered), NA_real_, Avg_questions_unanswered))
# export summary by country
crate_xlsx_by_country(db = by_country_totals,
exfile = glue::glue("data/6.data-collection/2.response_rates/responses_by_country_{Sys.Date()}.xlsx")
)
total_countries = length(unique(by_country$Country_name))
havent_submitted =sum(by_country$Submitted ==0)
perc_havent = scales::percent(havent_submitted/total_countries)
sample_n = nrow(sample)
open = 4168
open_perc =scales::percent(open/sample_n)
accessed = comp = by_country_totals$Accessed[by_country_totals$Country_name == 'TOTAL']
acc_pers = percent(accessed/sample_n,accuracy = .01)
comp = by_country_totals$Submitted[by_country_totals$Country_name == 'TOTAL']
comp_pers = percent(comp/sample_n, accuracy = .01)
knitr::combine_words(sort(by_country$Country_name[by_country$Submitted==0]), sep = ", ")
avg_unanswered = round(mean(status$n_questions_unanswered[status$interview__status == "Submitted"], na.rm = T),1)
max_unanswered = round(max(status$n_questions_unanswered[status$interview__status == "Submitted"], na.rm = T),1)
glue::glue('from the {total_countries} countries in the sample, {havent_submitted} ({perc_havent}) have not submitted any interview yet.')
glue::glue('{open} ({open_perc}) have opened the invitation email')
glue('{accessed} ({acc_pers}) have accessed')
glue('{comp} ({comp_pers}) have submitted')
glue('The submitted interview with the maximum number of unanswered question, has {max_unanswered} unanswered')
glue("The average submitted interview has a total of {avg_unanswered} question")
library(ggplot2)
library(extrafont)
#check response rates
all_responses <- list.files('data/6.data-collection/2.response_rates', pattern = "xlsx")
all_responses
reports <- lapply(all_responses, function(x){
r <- rio::import(file.path("data/6.data-collection/2.response_rates",x)) %>%
filter(Country_name == "TOTAL") %>%
mutate(date = str_remove_all(x, "responses_by_country_|.xlsx")) %>%
select(Submitted, Accessed, date)
}) %>% do.call(rbind,.)
clean_r <- reports %>%
mutate(date = lubridate::ymd(date)) %>%
pivot_longer(-date,
names_to = "status")
responses  = max(clean_r$value[clean_r$status == 'Submitted'])
rsponses_label = prettyNum(responses, big.mark = ",")
ggplot(clean_r,
aes(x = date,
y = value,
color = status)
) +
geom_line(size = 1) +
geom_point(size = 3) +
scale_x_date(date_breaks = '1 day', date_labels = "%b %d") +
scale_color_manual(name = "",
values = c('#019BAD', '#72B62C')) +
scale_y_continuous(
breaks = seq(0,responses +500, 500),
labels = function(x)prettyNum(seq(0,responses +500, 500), big.mark = ",")) +
theme_minimal() +
labs(y = "Counterparts",
x ="",
title = "Evolution of Responses",
subtitle = glue("CP Survey: {rsponses_label} counterparts have submitted their interview."),
caption = "Data: CP Survey | November 17 2023")+
theme(
plot.title.position = 'plot',
plot.title = element_text(size = 20, face = 'bold'),
plot.subtitle = element_text(size = 14),
axis.text.x = element_text(angle = 90),
axis.title.x = element_text(margin = margin(r = 20)),
legend.text = element_text(size = 11),
legend.position = 'top',
text = element_text(family = "Open Sans")
)
# str_remove_all(all_responses, "responses_by_country_|.xlsx")
ggplot(clean_r,
aes(x = date,
y = value,
color = status)
) +
geom_line(size = 1) +
geom_point(size = 3) +
scale_x_date(date_breaks = '1 day', date_labels = "%b %d") +
scale_color_manual(name = "",
values = c('#019BAD', '#72B62C')) +
scale_y_continuous(
breaks = seq(0,responses +500, 500),
labels = function(x)prettyNum(seq(0,responses +500, 500), big.mark = ",")) +
theme_minimal() +
labs(y = "Counterparts",
x ="",
title = "Evolution of Responses",
subtitle = glue("CP Survey: {rsponses_label} counterparts have submitted their interview."),
caption = "Data: CP Survey | November 23 2023")+
theme(
plot.title.position = 'plot',
plot.title = element_text(size = 20, face = 'bold'),
plot.subtitle = element_text(size = 14),
axis.text.x = element_text(angle = 90),
axis.title.x = element_text(margin = margin(r = 20)),
legend.text = element_text(size = 11),
legend.position = 'top',
text = element_text(family = "Open Sans")
)
1500 * 100
150000 / 2064.86
